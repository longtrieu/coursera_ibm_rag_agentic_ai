{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6021cc40-bd4d-462f-bb22-2c265848fb77",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28e1994-8b40-40ce-bb60-b6cf2494e684",
   "metadata": {},
   "source": [
    "# **Similarity Search by Hand**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd749a4d-ed77-494b-a290-5ad6af1bcb58",
   "metadata": {},
   "source": [
    "### Install Required Libraries\n",
    "\n",
    "Run the cell below to install the required libraries for this lab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e742d9a-80aa-48d2-86aa-7481c6ed20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers==4.1.0 | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252e601d-f0bc-4df4-8677-95fd9526bf68",
   "metadata": {},
   "source": [
    "### Restart the Kernel\n",
    "\n",
    "After the above cell finishes running and successfully installs required libraries, please restart the kernel by clicking on the `Restart the kernel` button as indicated on the image below, or by going to `Kernel` --> `Restart kernel...` in the file menu.\n",
    "\n",
    "![restart-jupyterlab-kernel.png](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/0oK423hHPyQ0BhXaflSvyg/restart-jupyterlab-kernel.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19422073-fdf0-418b-8946-09b9c132eecb",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9567287-6e57-4e38-9520-944b0c8168fb",
   "metadata": {},
   "source": [
    "For this lab, we will be using the following external libraries:\n",
    "\n",
    "\n",
    "*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n",
    "*   [`scipy`](https://scipy.org/) for additional mathematical operations not found in `numpy`.\n",
    "*   [`torch`](https://pytorch.org/) for vector operations, although this library is also typically used for deep learning.\n",
    "*   [`sentence_transformers`](https://sbert.net/) for obtaining vector embeddings from text data using pre-trained models.\n",
    "\n",
    "Run the cell below to import these libraries, along with the built-in [`math`](https://docs.python.org/3/library/math.html) module from Python’s standard library:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd1e577-2cf2-4acd-ad75-b93f9bf35e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc29660f-a77c-42e5-8372-bb7f2537b1da",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864e4408-b025-4c0f-8996-7c28a4afa94a",
   "metadata": {},
   "source": [
    "## Obtain Vector Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961b4d8e-29a4-47b4-a4f3-2762db9ccdd4",
   "metadata": {},
   "source": [
    "To calculate distance and similarity metrics, we first need to generate vector embeddings for some text documents. Let’s begin by defining a few example documents:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fda1de2-98f1-45f5-a95f-2f990e9eae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example documents\n",
    "documents = [\n",
    "    'Bugs introduced by the intern had to be squashed by the lead developer.',\n",
    "    'Bugs found by the quality assurance engineer were difficult to debug.',\n",
    "    'Bugs are common throughout the warm summer months, according to the entomologist.',\n",
    "    'Bugs, in particular spiders, are extensively studied by arachnologists.'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c4332e-1f52-4904-ab5e-369a2696949a",
   "metadata": {},
   "source": [
    "As shown above, there are four example documents, each consisting of a single sentence. These sentences are intentionally designed to be challenging for semantic similarity search.\n",
    "\n",
    "All four sentences begin with the word \"Bugs,\" but they refer to different meanings of the word depending on context. The first two sentences relate to software bugs in programming, while the last two refer to physical bugs, such as insects or spiders.\n",
    "\n",
    "The key to distinguishing between these meanings lies in the context, particularly the type of professional mentioned in each sentence. For example, if we replaced the word \"arachnologists\" (scientists who study spiders and other arthropods) in the last sentence with \"lead developers,\" the sentence would instead refer to programming bugs.\n",
    "\n",
    "Let's now define a model that will embed these text documents into numerical vectors:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c5f0e1-37dd-4e02-8f90-5526d5155619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b36ee8-9c64-4fec-918a-42b5f33ddf3c",
   "metadata": {},
   "source": [
    "The code above creates an instance of the SentenceTransformer class from the sentence_transformers library, which is commonly used to generate vector embeddings from pre-trained models.\n",
    "\n",
    "In this example, we’re using the [paraphrase-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2) model. It was trained on pairs of paraphrased sentences, with the goal of generating similar embeddings for sentences that express the same meaning. While the model was originally designed for paraphrase identification, it also performs well on general semantic similarity tasks—like the ones we’re exploring in this lab.\n",
    "\n",
    "Let's now use the model instance to encode the documents into embedding vectors:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c4611-c693-4cc8-a34f-985b1624a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "embeddings = model.encode(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959ddaa7-4228-4327-b78d-4df7ed3204ec",
   "metadata": {},
   "source": [
    "The function below implements the L2 distance formula. It first calculates the sum of the squared differences between corresponding elements, then returns the square root of that sum:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef370600-4b07-4b48-8291-81b4007e75e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_fn(vector1, vector2):\n",
    "    squared_sum = sum((x - y) ** 2 for x, y in zip(vector1, vector2))\n",
    "    return math.sqrt(squared_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6f9871-d321-4d3e-bb0a-3e562a30025f",
   "metadata": {},
   "source": [
    "#### Exercise 1 - Make the manual calculation more efficient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107a0f5e-59c3-441c-a0a5-216d6a1770b7",
   "metadata": {},
   "source": [
    "The code used to populate the `l2_dist_manual array` is not very efficient. First, it redundantly calculates the distance between a vector and itself, even though the L2 distance in such cases is always zero. Second, the array is symmetric—meaning the distance between vectors at indices $i$ and $j$ is the same as between $j$ and $i$. Therefore, each distance only needs to be computed once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce550c-4647-45cd-ade0-c35e02d9bcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_dist_manual_improved = np.zeros([4,4])\n",
    "for i in range(embeddings.shape[0]):\n",
    "    for j in range(embeddings.shape[0]):\n",
    "        if j > i:\n",
    "            l2_dist_manual_improved[i,j] = euclidean_distance_fn(embeddings[i], embeddings[j])\n",
    "        elif i > j:\n",
    "            l2_dist_manual_improved[i,j] = l2_dist_manual_improved[j,i]\n",
    "        else:\n",
    "            l2_dist_manual_improved[i,j] = 0\n",
    "\n",
    "l2_dist_manual_improved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d01efa-d052-4909-8abc-401f87840f95",
   "metadata": {},
   "source": [
    "The following calculates the L2 norms for all the vectors in the `embeddings` array. The calculation simply squares each vector component, sums across columns (note the `axis=1` parameter in the `sum`), and takes a square root:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4f1385-4df8-4619-ad89-59df46af4033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 norms\n",
    "l2_norms = np.sqrt(np.sum(embeddings**2, axis=1))\n",
    "l2_norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0ac48-c1e8-44ca-86a8-6ae78b6ebb54",
   "metadata": {},
   "source": [
    "Note that the result is a vector with 4 numbers, each of which corresponds to the L2 norm, or the magnitude, of each vector. In order to normalize the vectors to a lenght of one, we should divide each vector's components by the norm. However, in order to do that efficiently, let's reshape the `l2_norms` vector into a 4x1 array:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a274f9-9947-4676-86d3-1ff1274a232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 norms reshaped\n",
    "l2_norms_reshaped = l2_norms.reshape(-1,1)\n",
    "l2_norms_reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c75478c-eda7-466f-aa03-5256d03497cd",
   "metadata": {},
   "source": [
    "The following code calculates normalized embedding vectors by dividing every component in the vector by the vector's L2 norm:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff59fd0c-b0a4-4ca1-8378-56c91cd42966",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_embeddings_manual = embeddings/l2_norms_reshaped\n",
    "normalized_embeddings_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4dde66-c399-46cf-96b0-82f10d3de959",
   "metadata": {},
   "source": [
    "##### Exercise 2 - Verify that vectors are normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa4637-bd16-4c8f-8904-f63b743035d8",
   "metadata": {},
   "source": [
    "Verify that `normalized_embeddings_manual` are normalized vectors by making sure that the length of each vector is equal to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669487ab-1ebf-4741-8cdb-aab2e33695a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum(normalized_embeddings_manual**2, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278c093e-8a33-49b4-9214-cfb773161c7e",
   "metadata": {},
   "source": [
    "##### Exercise 3 - Similarity Search Using a Query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fe5bb2-8b75-446d-b56f-a6eff33d8819",
   "metadata": {},
   "source": [
    "In the above examples, we calculated similarity between 4 documents:\n",
    "\n",
    "```python\n",
    "documents = [\n",
    "    'Bugs introduced by the intern had to be squashed by the lead developer.',\n",
    "    'Bugs found by the quality assurance engineer were difficult to debug.',\n",
    "    'Bugs are common throughout the warm summer months, according to the entomologist.',\n",
    "    'Bugs, in particular spiders, are extensively studied by arachnologists.'\n",
    "]\n",
    "```\n",
    "\n",
    "Now, your task is to find which of these 4 documents is most similar to the query `Who is responsible for a coding project and fixing others' mistakes?` using cosine similarity. You can reuse the `documents` and `normalized_embeddings_manual` arrays in your answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e050653-a17a-4b4c-9caa-da324dffd3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "query = \"Who is responsible for a coding project and fixing others' mistakes?\"\n",
    "query_embedding = model.encode([query])\n",
    "\n",
    "# Normalize the query embedding\n",
    "normalized_query_embedding = torch.nn.functional.normalize(\n",
    "  torch.from_numpy(query_embedding)\n",
    ").numpy()\n",
    "\n",
    "# Calculate the cosine similarity between the query embedding and the embeddings\n",
    "cosine_similarity_query = normalized_embeddings_manual @ normalized_query_embedding.T\n",
    "\n",
    "# Get highest cosine similarity\n",
    "highest_position = cosine_similarity_query.argmax()\n",
    "\n",
    "# Find document with highest cosine similarity\n",
    "documents[highest_position]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d006000-231c-4377-9d48-bd356b42c35a",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "d427e1b04231146bc304f0c47eb6ab99bf399c31f31b9def273627cfadfc9a94"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
