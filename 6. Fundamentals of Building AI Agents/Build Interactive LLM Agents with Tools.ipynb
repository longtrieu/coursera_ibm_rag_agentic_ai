{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5c0158f-0816-4281-83d0-2ddc255f6b56",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4af518f-7fab-4ab5-8580-d8f536384ee2",
   "metadata": {},
   "source": [
    "# **Build Interactive LLM Agents with Tools**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de39de8c-7f53-471b-a5c9-8caafc2fcf3c",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dba168d-eae6-4dbe-8945-c2363931e88c",
   "metadata": {},
   "source": [
    "### Installing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120182de-506e-4c08-b6a0-810605b4efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain===0.3.25 | tail -n 1\n",
    "%pip install langchain-openai===0.3.19 | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a181143-4919-44fd-a414-85ca1834d3f9",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "Recommendation:Import all required libraries in one place (here):_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa130c60-4515-4792-bc47-ac64f5e1f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d010cbe9-7710-4949-be86-2e1bb634a7bc",
   "metadata": {},
   "source": [
    "Let's initialize the language model that will power your tool calling capabilities. This code sets up a GPT-4o-mini model using the OpenAI provider through LangChain's interface, which you'll use to process queries and decide which tools to call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad60dc01-f3d3-4674-891c-fe44b3e3857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134e645-c27e-4b32-a803-e8c565fa0edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE IF YOU ARE NOT RUNNING LOCALLY\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ibm import ChatWatsonx\n",
    "openai_llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    api_key = \"your openai api key here\",\n",
    ")\n",
    "watsonx_llm = ChatWatsonx(\n",
    "    model_id=\"ibm/granite-3-2-8b-instruct\",\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    project_id=\"your project id associated with the API key\",\n",
    "    api_key=\"your watsonx.ai api key here\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77de361-db77-48a7-adf8-863faab9deee",
   "metadata": {},
   "source": [
    "## Building an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c96884-5320-4186-8d4f-565715bb0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCallingAgent:\n",
    "    def __init__(self, llm):\n",
    "        self.llm_with_tools = llm.bind_tools(tools)\n",
    "        self.tool_map = tool_map\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        # Step 1: Initial user message\n",
    "        chat_history = [HumanMessage(content=query)]\n",
    "\n",
    "        # Step 2: LLM chooses tool\n",
    "        response = self.llm_with_tools.invoke(chat_history)\n",
    "        if not response.tool_calls:\n",
    "            return response.contet # Direct response, no tool needed\n",
    "        # Step 3: Handle first tool call\n",
    "        tool_call = response.tool_calls[0]\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        tool_call_id = tool_call[\"id\"]\n",
    "\n",
    "        # Step 4: Call tool manually\n",
    "        tool_result = self.tool_map[tool_name].invoke(tool_args)\n",
    "\n",
    "        # Step 5: Send result back to LLM\n",
    "        tool_message = ToolMessage(content=str(tool_result), tool_call_id=tool_call_id)\n",
    "        chat_history.extend([response, tool_message])\n",
    "\n",
    "        # Step 6: Final LLM result\n",
    "        final_response = self.llm_with_tools.invoke(chat_history)\n",
    "        return final_response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265bdb9-a834-48df-b6e0-442c0f098a91",
   "metadata": {},
   "source": [
    "## Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cbe674-da10-4f08-a9a0-3a9a435ed0a4",
   "metadata": {},
   "source": [
    "### Exercise 1: Create a new tool\n",
    "\n",
    "Use the example tool format provided in the notebook to create a new tool named `calculate_tip` that takes a `total_bill and tip_percent`, and returns the tip amount. </br>\n",
    "Define and invoke the tool with sample inputs like `total_bill=120`, `tip_percent=15`. </br>\n",
    "Create a `tool_map` with the `calculate_tip` tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef1c39-47bf-45ac-aedd-dffa418199e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate_tip(total_bill: int, tip_percent: int) -> int:\n",
    "    \"\"\"Calculate tip\"\"\"\n",
    "    return total_bill * tip_percent * 0.01\n",
    "\n",
    "inputs = {\n",
    "    \"total_bill\": 120,\n",
    "    \"tip_percent\": 15\n",
    "}\n",
    "calculate_tip.invoke(inputs)\n",
    "\n",
    "tool_map = {\n",
    "    \"calculate_tip\": calculate_tip\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c5cc35-d6b3-4cd2-bfea-4470feb706d5",
   "metadata": {},
   "source": [
    "### Exercise 2: Tool calling with an LLM\n",
    "\n",
    "Simulate a user query like \"How much should I tip on $60 at 20%?\". </br>\n",
    "Bind the tool to the predefined `llm` and prompt the LLM with the query above. Then parse the LLM response for the tool calling details and invoke the tool accordingly. Finally, take the entire chat history and prompt the LLM for a final output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9542d0b-1bc9-41f0-a2b5-cf165278357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How much should I tip on $60 at 20%?\"\n",
    "\n",
    "llm_with_tool = llm.bind_tools([calculate_tip])\n",
    "chat_history = [HumanMessage(content=query)]\n",
    "\n",
    "response = llm_with_tool.invoke(chat_history)\n",
    "\n",
    "tool_calls = response.tool_calls\n",
    "tool_name = tool_calls[0][\"name\"]\n",
    "tool_args = tool_calls[0][\"args\"]\n",
    "tool_call_id = tool_calls[0][\"id\"]\n",
    "\n",
    "tool_response = tool_map[tool_name].invoke(tool_args)\n",
    "tool_message = ToolMessage(content=tool_response, tool_call_id=tool_call_id)\n",
    "\n",
    "chat_history.extend([response, tool_message])\n",
    "\n",
    "result = llm_with_tool.invoke(chat_history)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d5afd1-8d05-4cd6-8ca6-29bf2faa8fef",
   "metadata": {},
   "source": [
    "### Exercise 3: Create a tip calculating agent\n",
    "\n",
    "Create an agent to automate the entire process you previously completed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d612b-6a60-4b2c-9fb2-0c45c449db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TipAgent:\n",
    "    def __init__(self, llm):\n",
    "        self.llm_with_tool = llm.bind_tools([calculate_tip])\n",
    "        self.tool_map = tool_map\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        chat_history = [HumanMessage(content=query)]\n",
    "        response = llm_with_tool.invoke(chat_history)\n",
    "\n",
    "        tool_calls = response.tool_calls\n",
    "        tool_name = tool_calls[0][\"name\"]\n",
    "        tool_args = tool_calls[0][\"args\"]\n",
    "        tool_call_id = tool_calls[0][\"id\"]\n",
    "\n",
    "        tool_response = tool_map[tool_name].invoke(tool_args)\n",
    "        tool_message = ToolMessage(content=tool_response, tool_call_id=tool_call_id)\n",
    "\n",
    "        chat_history.extend([response, tool_message])\n",
    "\n",
    "        return llm_with_tool.invoke(chat_history).content\n",
    "\n",
    "agent = TipAgent(llm)\n",
    "query = \"How much should I tip on $60 at 20%?\"\n",
    "agent.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac53bb7-afc3-41ef-a472-cfb7b8151b14",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\"> &#169; IBM Corporation. All rights reserved. <h3/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fecc6c3-ec11-4ddc-af65-31ee0197dbb5",
   "metadata": {},
   "source": [
    "<!-- ## Changelog\n",
    "\n",
    "| Date | Version | Changed by | Change Description |\n",
    "|------|--------|--------|---------|\n",
    "| 2024-06-06 | 0.1 |  P. Kravitz | ID review and edit. No code edits.Updated the copyright statement. Change log added. Instructional edits only for IBM style. Second person, accessibility, and other minor grammar edits.| -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "3ed25488039fa4c590a60c6be98ebd97e5fa32f9525446191ec94fcf70e9fc62"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
