{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ee278e-f524-43bb-9c4f-cb150cffcd69",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748c1cd4-dbe5-4b8f-9cb6-fe9956f74db8",
   "metadata": {},
   "source": [
    "# **Build a Tool Calling Agent**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e1c759-68ff-48a6-b53e-b4743df0c0a7",
   "metadata": {},
   "source": [
    "### Installing required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e66a41-4bce-4d93-aff9-961fc4c2ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install pytube\n",
    "%pip install youtube-transcript-api==1.1.0\n",
    "%pip install langchain-community==0.3.16\n",
    "%pip install langchain==0.3.23\n",
    "%pip install langchain-openai==0.3.14\n",
    "%pip install yt-dlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0e2e75-185d-47d9-90a6-143f6be518ae",
   "metadata": {},
   "source": [
    "### Importing required libraries\n",
    "\n",
    "_It is recommended that you import all required libraries in one place (here):_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca7814-7f61-43a3-9b51-836f41a78e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pytube import YouTube\n",
    "from langchain_core.tools import tool\n",
    "from IPython.display import display, JSON\n",
    "import yt_dlp\n",
    "from typing import List, Dict\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import ToolMessage\n",
    "import json\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Suppress pytube errors\n",
    "import logging\n",
    "pytube_logger = logging.getLogger('pytube')\n",
    "pytube_logger.setLevel(logging.ERROR)\n",
    "\n",
    "# Suppress yt-dlp warnings\n",
    "yt_dpl_logger = logging.getLogger('yt_dlp')\n",
    "yt_dpl_logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5687724-2831-4a3d-868f-eb944cff8be0",
   "metadata": {},
   "source": [
    "Let's initialize the language model that will power your tool calling capabilities. This code sets up a GPT-4o-mini model using the OpenAI provider through LangChain's interface, which you'll use to process queries and decide which tools to call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d55081-7fb4-4b02-bbec-2db1de061a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12794327-a45a-4078-9195-52021ba7c54f",
   "metadata": {},
   "source": [
    "# Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9da579-32f5-4120-b329-c50d85e55e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def extract_video_id(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the 11-character YouTube video ID from a URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): A YouTube URL containing a video ID.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted video ID or error message if parsing fails.\n",
    "    \"\"\"\n",
    "\n",
    "    # Regex pattern to match video IDs\n",
    "    pattern = r'(?:v=|be/|embed/)([a-zA-Z0-9_-]{11})'\n",
    "    match = re.search(pattern, url)\n",
    "    return match.group(1) if match else \"Error: Invalid YouTube URL\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f80e80-dae1-4ae5-9a9d-97f5ff7de3ad",
   "metadata": {},
   "source": [
    "## Tool list \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa111760-e41b-4f46-a820-cab319bddf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = []\n",
    "tools.append(extract_video_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbbc0cc-9347-4793-bdef-2f0f6af6295c",
   "metadata": {},
   "source": [
    "### Defining transcript fetching tool\n",
    "\n",
    "This tool uses the `YouTubeTranscriptApi` library to retrieve the captions or subtitles from a video. You'll be taking the video ID (which can be extracted using your previous tool) and an optional language parameter. The function attempts to get the transcript and joins all text segments into a continuous string, or returns an error message if the transcript can't be retrieved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c0f27-feef-482f-84a8-3d907d91f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "\n",
    "@tool\n",
    "def fetch_transcript(video_id: str, language: str = \"en\") -> str:\n",
    "    \"\"\"\n",
    "    Fetches the transcript of a YouTube video.\n",
    "\n",
    "    Args:\n",
    "        video_id (str): The YouTube video ID (e.g., \"dQw4w9WgXcQ\").\n",
    "        language (str): Language code for the transcript (e.g., \"en\", \"es\").\n",
    "\n",
    "    Returns:\n",
    "        str: The transcript text or an error message.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        ytt_api = YouTubeTranscriptApi()\n",
    "        transcript = ytt_api.fetch(video_id, languages=[language])\n",
    "        return \" \".join([snippet.text for snippet in transcript.snippets])\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c507b87-edc8-4dc8-9f13-45424bcb5873",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.append(fetch_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0d920e-a2d7-4ff6-8e0b-a9831b9a5e42",
   "metadata": {},
   "source": [
    "### Defining YouTube search tool\n",
    "\n",
    "This tool uses the `Search` class from the PyTube library to perform searches on YouTube. When given a search term, it returns a list of matching videos with each video represented as a dictionary containing the title, video ID, and a shortened URL. This tool will be helpful for discovering relevant videos when you don't already have a specific URL in mind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8f19d0-30fe-44a6-a992-a8c18c37418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import Search\n",
    "from langchain.tools import tool\n",
    "from typing import List, Dict\n",
    "\n",
    "@tool\n",
    "def search_youtube(query: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Search YouTube for videos matching the query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search term to look for on YouTube\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries containing video titles and IDs in format:\n",
    "        [{'title': 'Video Title', 'video_id': 'abc123'}, ...]\n",
    "        Returns error message if search fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        s = Search(query)\n",
    "        return [\n",
    "            {\n",
    "                \"title\": yt.title,\n",
    "                \"video_id\": yt.video_id,\n",
    "                \"url\": f\"https://youtu.be/{yt.video_id}\"\n",
    "            }\n",
    "            for yt in s.results\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1708e81-e2dd-4ac7-a087-07b1321df9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.append(search_youtube)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd5efbc-e847-4859-9549-405c4798ed11",
   "metadata": {},
   "source": [
    "### Defining metadata extraction tool\n",
    "\n",
    "This tool takes a YouTube URL and returns comprehensive information about the video, including its title, view count, duration, channel name, like count, comment count, and any chapter markers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a61a0e-0da6-4dad-a8ca-75cf16be9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_full_metadata(url: str) -> dict:\n",
    "    \"\"\"Extract metadata given a YouTube URL, including title, views, duration, channel, likes, comments, and chapters.\"\"\"\n",
    "    with yt_dlp.YoutubeDL({'quiet': True, 'logger': yt_dpl_logger}) as ydl:\n",
    "        info = ydl.extract_info(url, download=False)\n",
    "        return {\n",
    "            'title': info.get('title'),\n",
    "            'views': info.get('view_count'),\n",
    "            'duration': info.get('duration'),\n",
    "            'channel': info.get('uploader'),\n",
    "            'likes': info.get('like_count'),\n",
    "            'comments': info.get('comment_count'),\n",
    "            'chapters': info.get('chapters', [])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c88a48d-3064-44fe-9ea8-68214a6edb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.append(get_full_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30bec6b-b9d2-4f9e-93d5-f084e869caae",
   "metadata": {},
   "source": [
    "### Defining trending videos tool\n",
    "\n",
    "This tool uses `yt-dlp` to access YouTube's trending feed based on a provided country code (like \"US\" for the United States or \"IN\" for India). It collects important information about each trending video, including the title, video ID, URL, channel name, duration, and view count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae63a3-1f5f-4bcc-9a18-43894e45c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "@tool\n",
    "def get_trending_videos(region_code: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Fetches currently trending YouTube videos for a specific region.\n",
    "\n",
    "    Args:\n",
    "        region_code (str): 2-letter country code (e.g., \"US\", \"IN\", \"GB\")\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries with video details: title, video_id, channel, view_count, duration\n",
    "    \"\"\"\n",
    "    ydl_opts = {\n",
    "        'geo_bypass_country': region_code.upper(),\n",
    "        'extract_flat': True,\n",
    "        'quiet': True,\n",
    "        'force_generic_extractor': True,\n",
    "        'logger': yt_dpl_logger\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            info = ydl.extract_info(\n",
    "                'https://www.youtube.com/feed/trending',\n",
    "                download=False\n",
    "            )\n",
    "\n",
    "            trending_videos = []\n",
    "            for entry in info['entries']:\n",
    "                video_data = {\n",
    "                    'title': entry.get('title', 'N/A'),\n",
    "                    'video_id': entry.get('id', 'N/A'),\n",
    "                    'url': entry.get('url', 'N/A'),\n",
    "                    'channel': entry.get('uploader', 'N/A'),\n",
    "                    'duration': entry.get('duration', 0),\n",
    "                    'view_count': entry.get('view_count', 0)\n",
    "                }\n",
    "                trending_videos.append(video_data)\n",
    "\n",
    "            return trending_videos[:25]  # Return top 25 trending videos\n",
    "\n",
    "    except Exception as e:\n",
    "        return [{'error': f\"Failed to fetch trending videos: {str(e)}\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9575a41-755d-4310-b53d-1347c69eb477",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.append(get_trending_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76417c3-503f-434b-9fd3-aa569e744944",
   "metadata": {},
   "source": [
    "### Defining thumbnail retrieval tool\n",
    "\n",
    "This tool uses `yt-dlp` to retrieve information about the various thumbnail images that YouTube generates for videos at different resolutions. For each thumbnail, collect its URL, width, height, and formatted resolution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde78bb-7462-4ecb-b992-19ab3f8590bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_thumbnails(url: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Get available thumbnails for a YouTube video using its URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): YouTube video URL (any format)\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries with thumbnail URLs and resolutions in YouTube's native order\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL({'quiet': True, 'logger': yt_dpl_logger}) as ydl:\n",
    "            info = ydl.extract_info(url, download=False)\n",
    "\n",
    "            thumbnails = []\n",
    "            for t in info.get('thumbnails', []):\n",
    "                if 'url' in t:\n",
    "                    thumbnails.append({\n",
    "                        \"url\": t['url'],\n",
    "                        \"width\": t.get('width'),\n",
    "                        \"height\": t.get('height'),\n",
    "                        \"resolution\": f\"{t.get('width', '')}x{t.get('height', '')}\".strip('x')\n",
    "                    })\n",
    "\n",
    "            return thumbnails\n",
    "\n",
    "    except Exception as e:\n",
    "        return [{\"error\": f\"Failed to get thumbnails: {str(e)}\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f1ecdf-67c8-4acf-85ba-d8c251fc19f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.append(get_thumbnails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b351321-5922-4850-859e-6ee01adf0106",
   "metadata": {},
   "source": [
    "##  Binding tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae000a00-0641-4aa8-950b-edb5b772279d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now, you'll bind your collection of tools to the language model. It enables the LLM to access and use your custom YouTube tools during conversations. By binding the tools, you're giving the model the ability to call these functions when it determines they're needed to fulfill a user request, making the LLM aware of your tools' capabilities and how to use them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa9beb1-5b7a-4a25-8aea-9887c95f4be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd2058-b602-41fa-b203-0dd47a5e7318",
   "metadata": {},
   "source": [
    "#### Creating a tool mapping dictionary\n",
    "\n",
    "Now you'll create a dictionary that maps tool names to their corresponding function objects. This mapping will be useful later when you need to programmatically invoke specific tools based on their names. It allows you to easily look up and execute a tool function when you have only the tool name as a string, which will be important when processing tool calls from the language model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0997858-c3bd-416f-b4ec-db970eb09db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_mapping = {\n",
    "    \"get_thumbnails\" : get_thumbnails,\n",
    "    \"get_trending_videos\": get_trending_videos,\n",
    "    \"extract_video_id\": extract_video_id,\n",
    "    \"fetch_transcript\": fetch_transcript,\n",
    "    \"search_youtube\": search_youtube,\n",
    "    \"get_full_metadata\": get_full_metadata\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e9278e-54b8-4f57-83f6-932ffa74f809",
   "metadata": {},
   "source": [
    "### Automating the tool calling process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053de2e1-df4b-4469-be6a-a03b52819541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the processing steps\n",
    "def execute_tool(tool_call):\n",
    "    \"\"\"Execute single tool call and return ToolMessage\"\"\"\n",
    "    try:\n",
    "        result = tool_mapping[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "        return ToolMessage(\n",
    "            content=str(result),\n",
    "            tool_call_id=tool_call[\"id\"]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return ToolMessage(\n",
    "            content=f\"Error: {str(e)}\",\n",
    "            tool_call_id=tool_call[\"id\"]\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56207c0-f692-47ba-a25d-7718b876483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bbddd0-d72d-497d-ab46-745bce0aa1f1",
   "metadata": {},
   "source": [
    "## Building the summarization chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e3e47-c0fd-4d23-b627-d704afd842af",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_chain = (\n",
    "    # Start with initial query\n",
    "    RunnablePassthrough.assign(\n",
    "        messages=lambda x: [HumanMessage(content=x[\"query\"])]\n",
    "    )\n",
    "    # First LLM call (extract video ID)\n",
    "    | RunnablePassthrough.assign(\n",
    "        ai_response=lambda x: llm_with_tools.invoke(x[\"messages\"])\n",
    "    )\n",
    "    # Process first tool call\n",
    "    | RunnablePassthrough.assign(\n",
    "        tool_messages=lambda x: [\n",
    "            execute_tool(tc) for tc in x[\"ai_response\"].tool_calls\n",
    "        ]\n",
    "    )\n",
    "    # Update message history\n",
    "    | RunnablePassthrough.assign(\n",
    "        messages=lambda x: x[\"messages\"] + [x[\"ai_response\"]] + x[\"tool_messages\"]\n",
    "    )\n",
    "    # Second LLM call (fetch transcript)\n",
    "    | RunnablePassthrough.assign(\n",
    "        ai_response2=lambda x: llm_with_tools.invoke(x[\"messages\"])\n",
    "    )\n",
    "    # Process second tool call\n",
    "    | RunnablePassthrough.assign(\n",
    "        tool_messages2=lambda x: [\n",
    "            execute_tool(tc) for tc in x[\"ai_response2\"].tool_calls\n",
    "        ]\n",
    "    )\n",
    "    # Final message update\n",
    "    | RunnablePassthrough.assign(\n",
    "        messages=lambda x: x[\"messages\"] + [x[\"ai_response2\"]] + x[\"tool_messages2\"]\n",
    "    )\n",
    "    # Generate final summary\n",
    "    | RunnablePassthrough.assign(\n",
    "        summary=lambda x: llm_with_tools.invoke(x[\"messages\"]).content\n",
    "    )\n",
    "    # Return just the summary text\n",
    "    | RunnableLambda(lambda x: x[\"summary\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e39e3-05c3-4663-b8b3-9d847ce306b0",
   "metadata": {},
   "source": [
    "#### Creating the initial message setup\n",
    "\n",
    "Here you're setting up the first step of your chain that will handle the initial user query. The `RunnablePassthrough.assign` creates a component that takes an input dictionary containing a \"query\" and converts it into a list containing a single `HumanMessage` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb8783-ec9c-4259-9302-d5e48ce5198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_setup = RunnablePassthrough.assign(\n",
    "    messages=lambda x: [HumanMessage(content=x[\"query\"])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc5043-17de-4c6f-8e07-da06f713565e",
   "metadata": {},
   "source": [
    "#### Defining the first LLM interaction\n",
    "\n",
    "Here, you'll create the second step of your chain, which handles the first interaction with the language model. This component takes the formatted messages from the previous step, sends them to your tool-equipped LLM, and captures the response in a field called \"ai_response.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c2a05-6a4f-4165-b7df-9e3c757b57ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_llm_call = RunnablePassthrough.assign(\n",
    "    ai_response=lambda x: llm_with_tools.invoke(x[\"messages\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a64dbff-f7fe-4ee9-94d9-695386020c56",
   "metadata": {},
   "source": [
    "#### Processing the first tool call\n",
    "\n",
    "Here, you're defining the processing step that handles the LLM's first tool call. This component:\n",
    "1. Executes each tool call by passing it to your `execute_tool` function, which runs the appropriate tool and returns the result as a `ToolMessage`\n",
    "2. Updates the message history by combining the original messages, the LLM's response, with the tool calls, and the tool results\n",
    "3. Prepares the updated conversation state for the next interaction with the LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3bffba-5fd1-49d2-9b89-b90bc4f64ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tool_processing = RunnablePassthrough.assign(\n",
    "    tool_messages=lambda x: [\n",
    "        execute_tool(tc) for tc in x[\"ai_response\"].tool_calls\n",
    "    ]\n",
    ").assign(\n",
    "    messages=lambda x: x[\"messages\"] + [x[\"ai_response\"]] + x[\"tool_messages\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08afdb2-6bda-48b0-8947-c74010deae86",
   "metadata": {},
   "source": [
    "#### Defining the second LLM interaction\n",
    "\n",
    "Here, you're creating the next step in your chain that handles the second interaction with the language model. This component takes the updated message history (which now includes the results from the first tool call) and sends it to the LLM again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d531d-bf8d-4d94-91d4-2b2935884186",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_llm_call = RunnablePassthrough.assign(\n",
    "    ai_response2=lambda x: llm_with_tools.invoke(x[\"messages\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaa3065-1ca0-4acd-aadc-a5a88edadccd",
   "metadata": {},
   "source": [
    "#### Processing the second tool call\n",
    "\n",
    "Here, you're defining the processing step that handles the LLM's second tool call. Similar to the first tool processing step, this component executes the tool calls (typically fetching the transcript), creates tool messages with the results, and updates the message history by combining everything for the final summarization step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0608148-1b1a-46d1-a67b-6b7bea819f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_tool_processing = RunnablePassthrough.assign(\n",
    "    tool_messages2=lambda x: [\n",
    "        execute_tool(tc) for tc in x[\"ai_response2\"].tool_calls\n",
    "    ]\n",
    ").assign(\n",
    "    messages=lambda x: x[\"messages\"] + [x[\"ai_response2\"]] + x[\"tool_messages2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41dc844-049e-4bac-bf70-db5d2b2bade7",
   "metadata": {},
   "source": [
    "#### Generating the final summary\n",
    "\n",
    "Here, you're defining the final step that produces the summary of the YouTube video. This component:\n",
    "1. Takes the complete message history (which now contains the original query, tool calls, and tool results)\n",
    "2. Invokes the LLM one last time to generate a summary\n",
    "3. Extracts just the content field from the LLM's response\n",
    "4. Uses a RunnableLambda to return only the summary text as the final output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e15c5-933a-4f14-90b9-b4262a88344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary = RunnablePassthrough.assign(\n",
    "    summary=lambda x: llm_with_tools.invoke(x[\"messages\"]).content\n",
    ") | RunnableLambda(lambda x: x[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f63909-f2f5-4456-9d43-b7de39f3d02a",
   "metadata": {},
   "source": [
    "#### Assembling the complete chain\n",
    "\n",
    "Now, you're combining all the individual components you've defined into a single cohesive chain. By piping each step to the next, you'll create a workflow that:\n",
    "1. Formats the initial query\n",
    "2. Gets the first LLM response (video ID extraction)\n",
    "3. Processes the first tool call\n",
    "4. Gets the second LLM response (transcript request)\n",
    "5. Processes the second tool call\n",
    "6. Generates the final summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4719bfd-6af5-400e-8c24-eaebff80debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    initial_setup\n",
    "    | first_llm_call\n",
    "    | first_tool_processing\n",
    "    | second_llm_call\n",
    "    | second_tool_processing\n",
    "    | final_summary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50967fe-53e1-4186-9027-3d5e4e3c4c7a",
   "metadata": {},
   "source": [
    "## Recursive chain flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc792dd-fa03-4be1-af6d-b0e5170c1357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableBranch, RunnableLambda\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "import json\n",
    "\n",
    "def execute_tool(tool_call):\n",
    "    \"\"\"Execute single tool call and return ToolMessage\"\"\"\n",
    "    try:\n",
    "        result = tool_mapping[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "        content = json.dumps(result) if isinstance(result, (dict, list)) else str(result)\n",
    "    except Exception as e:\n",
    "        content = f\"Error: {str(e)}\"\n",
    "\n",
    "    return ToolMessage(\n",
    "        content=content,\n",
    "        tool_call_id=tool_call[\"id\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d099144-de20-43cf-aa3d-d9a60646e22e",
   "metadata": {},
   "source": [
    "#### Defining the core processing logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1079d30d-9521-4658-b974-57f6a4a6746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tool_calls(messages):\n",
    "    \"\"\"Recursive tool call processor\"\"\"\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # Execute all tool calls in parallel\n",
    "    tool_messages = [\n",
    "        execute_tool(tc)\n",
    "        for tc in getattr(last_message, 'tool_calls', [])\n",
    "    ]\n",
    "\n",
    "    # Add tool responses to message history\n",
    "    updated_messages = messages + tool_messages\n",
    "\n",
    "    # Get next LLM response\n",
    "    next_ai_response = llm_with_tools.invoke(updated_messages)\n",
    "\n",
    "    return updated_messages + [next_ai_response]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00937d70-f12b-4c52-ac00-dd97be1e0030",
   "metadata": {},
   "source": [
    "#### Creating the recursive stopping condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc9764c-ee23-4dd9-b52c-57ad62b23cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(messages):\n",
    "    \"\"\"Check if you need another iteration\"\"\"\n",
    "    last_message = messages[-1]\n",
    "    return bool(getattr(last_message, 'tool_calls', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8a9f0b-7c95-4e98-aca5-784a08e355d1",
   "metadata": {},
   "source": [
    "\n",
    "#### Implementing the recursive function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230d34a2-1dc6-4b85-bdec-99153fa1b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _recursive_chain(messages):\n",
    "    \"\"\"Recursively process tool calls until completion\"\"\"\n",
    "    if should_continue(messages):\n",
    "        new_messages = process_tool_calls(messages)\n",
    "        return _recursive_chain(new_messages)\n",
    "    return messages\n",
    "\n",
    "recursive_chain = RunnableLambda(_recursive_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160115f0-302b-4d6f-bc42-596b6eb13b72",
   "metadata": {},
   "source": [
    "#### Building the complete universal chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49730c-d4b1-4ac8-bc48-13de30ee5871",
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_chain = (\n",
    "    RunnableLambda(lambda x: [HumanMessage(content=x[\"query\"])])\n",
    "    | RunnableLambda(lambda messages: messages + [llm_with_tools.invoke(messages)])\n",
    "    | recursive_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf62458-b389-415d-aee2-c471cd415ebf",
   "metadata": {},
   "source": [
    "# Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f67b686-1b38-4883-a32b-d3a75478e78d",
   "metadata": {},
   "source": [
    "### Exercise 1: Try a different video with a Youtube link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca0904-2c78-41c2-a8a3-aca65e869839",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=m6G8k9dQ8S8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d469a3d-671f-489c-b1a9-698e3bebb006",
   "metadata": {},
   "source": [
    "### Exercise 2: Extract the video ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1eb0c-3392-4a40-8380-1de126c48202",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = extract_video_id.run(video_url)\n",
    "print(f\"Extracted video ID: {video_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63fa667-c28f-45a7-ad95-725287fc83f4",
   "metadata": {},
   "source": [
    "### Exercise 3: Collect all necessary data about the video in one go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1e54e-9997-450a-ac47-a319e45e73b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadata = get_full_metadata.run(video_url)\n",
    "print(f\"Retrieved metadata for: {video_metadata['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902f1de2-9ff0-4b66-aeba-5876787f10d2",
   "metadata": {},
   "source": [
    "### Exercise 4: Get video transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818862c4-62be-4a9e-a3c3-8e346dfe85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = fetch_transcript.run(video_url)\n",
    "print(f\"Retrieved transcript with {len(transcript)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea13bfb-f1ca-49ae-b99a-246a80da3ed1",
   "metadata": {},
   "source": [
    "### Exercise 5: Get video thumbnails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83904ead-ec86-4941-a0e7-84e3c2de22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnails = get_thumbnails.run(video_url)\n",
    "print(f\"Retrieved {len(thumbnails)} thumbnails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31893b59-5027-4be2-b87e-196bd43ef439",
   "metadata": {},
   "source": [
    "### Let's have a comprehensive prompt to be passed to LLM to generate a summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decd40d6-74b6-4624-a343-d598a6c6a1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Please analyze this YouTube video and provide a comprehensive summary.\n",
    "\n",
    "VIDEO TITLE: {video_metadata['title']}\n",
    "CHANNEL: {video_metadata['channel']}\n",
    "VIEWS: {video_metadata['views']}\n",
    "DURATION: {video_metadata['duration']} seconds\n",
    "LIKES: {video_metadata['likes']}\n",
    "\n",
    "TRANSCRIPT EXCERPT:\n",
    "{transcript[:3000]}... (transcript truncated for brevity)\n",
    "\n",
    "Based on this information, please provide:\n",
    "1. A concise summary of the video content (3-5 bullet points)\n",
    "2. The main topics or themes discussed\n",
    "3. The intended audience for this content\n",
    "4. A brief analysis of why this video might be performing well (or not)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2be0ee2-8380-47f7-8904-592350746d94",
   "metadata": {},
   "source": [
    "### Exercise 6: Single LLM invocation with all the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748ea839-1074-4b9d-b2d1-96246427fffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=prompt)]\n",
    "response = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5839082f-d6a6-43a6-b9dc-e4e8741cb09d",
   "metadata": {},
   "source": [
    "### Exercise 7: Display the comprehensive analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4589d5fd-bd4f-41a9-ac84-08b37d81f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== VIDEO ANALYSIS =====\\n\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bedd3c2-a210-45ba-844c-0f7a6f50a262",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "535e148d01d12998c9766a3ee8486df2976a4646226066d61e82f992ec66f89a"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
