{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71237dcb-e454-472b-83cd-41086f5bfbea",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7b155b-e227-4ffd-94c0-0e35e62f1353",
   "metadata": {},
   "source": [
    "# **Building a Reflection Agent with LangGraph**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f9750-0897-402e-87fc-82a92a6c4a66",
   "metadata": {},
   "source": [
    "### Installing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa9d824-9d00-41c1-88ec-e70aaff9f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q langgraph==0.3.31\n",
    "%pip install -q langchain-ibm==0.3.10\n",
    "%pip install -q langchain==0.3.23\n",
    "%pip install -q langchain_community==0.3.21\n",
    "%pip install -q pygraphviz==1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c318c40e-1c3f-4c25-9414-aaf94083582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ibm import ChatWatsonx\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph import END, MessageGraph, StateGraph\n",
    "\n",
    "from typing import List, Sequence\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e4e5ce-9a91-4a8e-beb1-fec433b64a02",
   "metadata": {},
   "source": [
    "### **Instantiating the Language Model**\n",
    "\n",
    "This step initializes the **`ChatWatsonx`** language model, which will be used to generate responses based on the prompts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc602399-ff5d-48e4-bff2-36b7821492d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatWatsonx(\n",
    "    model_id=\"ibm/granite-3-3-8b-instruct\",\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    project_id=\"skills-network\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd0d6f3-444c-489d-b288-831037474497",
   "metadata": {},
   "source": [
    "### **Generation Prompt for Posts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d811dbf0-ca82-41e1-bb7e-28fbca7fa1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a professional LinkedIn content assistant tasked with crafting engaging, insightful, and well-structured LinkedIn posts.\"\n",
    "            \" Generate the best LinkedIn post possible for the user's request.\"\n",
    "            \" If the user provides feedback or critique, respond with a refined version of your previous attempts, improving clarity, tone, or engagement as needed.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91e1d0-c76a-488e-a081-29f0f7161c1c",
   "metadata": {},
   "source": [
    "### **Creating the Chain for LinkedIn Post Generation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5c4366-78ae-4515-91fd-343e0acc1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_chain = generation_prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc23605-f906-4921-bba1-eca0cac3734c",
   "metadata": {},
   "source": [
    "### **Reflection Prompt for LinkedIn Post Critique**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c1f6d-5637-498c-bf11-cfaf3c7d3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"You are a professional LinkedIn content strategist and thought leadership expert. Your task is to critically evaluate the given LinkedIn post and provide a comprehensive critique. Follow these guidelines:\n",
    "\n",
    "        1. Assess the post’s overall quality, professionalism, and alignment with LinkedIn best practices.\n",
    "        2. Evaluate the structure, tone, clarity, and readability of the post.\n",
    "        3. Analyze the post’s potential for engagement (likes, comments, shares) and its effectiveness in building professional credibility.\n",
    "        4. Consider the post’s relevance to the author’s industry, audience, or current trends.\n",
    "        5. Examine the use of formatting (e.g., line breaks, bullet points), hashtags, mentions, and media (if any).\n",
    "        6. Evaluate the effectiveness of any call-to-action or takeaway.\n",
    "\n",
    "        Provide a detailed critique that includes:\n",
    "        - A brief explanation of the post’s strengths and weaknesses.\n",
    "        - Specific areas that could be improved.\n",
    "        - Actionable suggestions for enhancing clarity, engagement, and professionalism.\n",
    "\n",
    "        Your critique will be used to improve the post in the next revision step, so ensure your feedback is thoughtful, constructive, and practical.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42479be-867d-4ce3-9742-2a4de98c8510",
   "metadata": {},
   "source": [
    "### **Creating the Reflect Chain**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd355a4-76de-4046-b574-d09d5808d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflect_chain = reflection_prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148dd6ab-e314-4075-bf95-e79f57addf89",
   "metadata": {},
   "source": [
    "#### **Initializing `MessageGraph`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacb6f67-7bcf-4bcd-962d-93c8eb859d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessageGraph\n",
    "from typing import List, Annotated, TypedDict\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# Initialize a predefined MessageGraph\n",
    "graph = MessageGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a1adeb-4f8e-40cf-a5de-a8c23af387b8",
   "metadata": {},
   "source": [
    "\n",
    "### **Defining the Generation and Reflection  Node**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8120fa-4382-4147-9ed9-1d7a9a3da5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_node(state: Sequence[BaseMessage]) -> List[BaseMessage]:\n",
    "    generated_post = generate_chain.invoke({\"messages\": state})\n",
    "    return [AIMessage(content=generated_post.content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f7de6-434f-4135-b301-1a4128b0d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_node(messages: Sequence[BaseMessage]) -> List[BaseMessage]:\n",
    "    res = reflect_chain.invoke({\"messages\": messages})  # Passes messages as input to reflect_chain\n",
    "    return [HumanMessage(content=res.content)]  # Returns the refined message as HumanMessage for feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7956ed-43ea-4b33-a58f-e1b45a7f9cba",
   "metadata": {},
   "source": [
    "### **Adding the Generate Node to the Graph**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f218d-379f-4b58-8f1a-0951bb7930dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_node(\"generate\", generation_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb7122b-4747-4ef4-98ea-92aea72452e2",
   "metadata": {},
   "source": [
    "### **Adding the Reflect Node to the Graph**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c9840b-86c9-456f-b855-39ed7536b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_node(\"reflect\", reflection_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1682a664-2b5c-43d5-a485-672ab040fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_edge(\"reflect\", \"generate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc14d067-e077-4808-b3ef-7d586f777326",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.set_entry_point(\"generate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a045a7-5f5b-483a-b95e-35360c928291",
   "metadata": {},
   "source": [
    "### **Adding a Router Node for Decision Making**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330825f-6dff-4483-8b84-4a8c4b2decbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: List[BaseMessage]):\n",
    "    print(state)\n",
    "    print(len(state))\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    if len(state) > 6:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706c6c22-2e5b-4573-81f7-55c665c14226",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_conditional_edges(\"generate\", should_continue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f37da1-cd20-4635-9cb9-b257be827302",
   "metadata": {},
   "source": [
    "### **Compiling the Workflow**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b662d7a5-0ea3-4cd7-a33f-bd259075aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81494316-472e-4fdc-b23e-e8596c72f445",
   "metadata": {},
   "source": [
    "### **Defining Inputs for the Workflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c71e97-3751-417e-bde9-54566d7a486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = HumanMessage(content=\"\"\"Write a linkedin post on getting a software developer job at IBM under 160 characters\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012ba3b4-67aa-4e53-af69-a08d2c1390ec",
   "metadata": {},
   "source": [
    "### **Executing the Workflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16320032-6c60-45e5-a6b4-9d7f761659f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = workflow.invoke(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2544edf-ebf2-4f4e-a6b1-0b4a7291e5a5",
   "metadata": {},
   "source": [
    "#### **Plotting the Graph**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c435cc8-f02e-45eb-b096-4aaeb88aef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(workflow.get_graph().draw_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de70297-1a7c-40b1-8d05-6f0c15b10f0a",
   "metadata": {},
   "source": [
    "Copyright © 2025 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "1893c8e00bcf2d7b210b489875bf3855983e443d9e2ef23b5169ddfa7f2560a2"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
